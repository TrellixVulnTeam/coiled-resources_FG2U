{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5e507d-8b43-4d55-b297-248aed014d85",
   "metadata": {},
   "source": [
    "Notebook goal:\n",
    "\n",
    "- predict the tip size\n",
    "\n",
    "Structure:\n",
    "\n",
    "- load the data\n",
    "- transform into required shape\n",
    "- train (note will use a hard, time-based split)\n",
    "- predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfecffa-151b-4693-be01-997b68052a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a73512993fa40f7841f3133107b5b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from coiled import Cluster\n",
    "from distributed import Client\n",
    "\n",
    "cluster = Cluster(\n",
    "    software=\"taxi-xgboost\",\n",
    "    n_workers=2,\n",
    "    worker_cpu=[2, 12],\n",
    "    worker_memory=[\"32GB\", \"64GB\"],\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09bd158-1e76-44e9-8241-06d582c13e97",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900f5e78-db98-458a-90bf-ae1e2902c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.dataframe import concat, read_parquet\n",
    "from dask_optuna import DaskStorage\n",
    "from joblib import parallel_backend\n",
    "from numpy import exp, log1p\n",
    "from optuna import create_study\n",
    "from sklearn.compose import TransformedTargetRegressor, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, PolynomialFeatures\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c0afc-7bba-4087-aae5-baec15437cce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load data and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73c5a75-d7ef-4a9c-a4b0-6b82fbca1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_aggreate(year, month):\n",
    "    \"\"\"Load data for a particular year/month and aggregate to the required format.\"\"\"\n",
    "\n",
    "    # optimize data usage by loading columns of interest only\n",
    "    use_cols = [\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"tpep_pickup_datetime\",\n",
    "        # \"tpep_dropoff_datetime\",\n",
    "        \"passenger_count\",\n",
    "        \"total_amount\",\n",
    "        # \"trip_distance\",\n",
    "        # \"tip_amount\",\n",
    "    ]\n",
    "\n",
    "    PATH_DATA = \"s3://nyc-tlc/trip data/yellow_tripdata_{year}-{month:02}*.parquet\"\n",
    "\n",
    "    ddf = read_parquet(PATH_DATA.format(year=year, month=month), columns=use_cols)\n",
    "\n",
    "    frequency = \"1D\"\n",
    "    ddf[\"rounded_time\"] = ddf[\"tpep_pickup_datetime\"].dt.floor(frequency)\n",
    "\n",
    "    ddf[\"trip_count\"] = 1\n",
    "\n",
    "    # aggregate the data to necessary format\n",
    "    aggregations = {\n",
    "        \"trip_count\": \"sum\",\n",
    "        \"passenger_count\": \"sum\",\n",
    "        \"total_amount\": \"sum\",\n",
    "    }\n",
    "\n",
    "    ddf_agg = ddf.groupby([\"rounded_time\", \"PULocationID\"]).agg(aggregations)\n",
    "    for c in ddf_agg.columns:\n",
    "        ddf_agg[c] = ddf_agg[c].clip(lower=0)\n",
    "\n",
    "    return ddf_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b60f613-8d7d-4e18-b3ce-1647c1b2b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = concat(\n",
    "    [\n",
    "        load_and_aggreate(year, month)\n",
    "        for year in range(2012, 2016 + 1)\n",
    "        for month in range(1, 12 + 1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2b6b07e-050d-4d70-8e9e-3f50468fa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist to avoid recomputes when using optuna\n",
    "ddf = ddf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff86c37-11e4-46e4-a3bc-1e9994f7d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient parallel processing and aggregation\n",
    "# the result is small, so can load it into memory\n",
    "df = ddf.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c0ecf-88bf-414f-a381-af949c29fa25",
   "metadata": {},
   "source": [
    "# add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5edfe53-3fc0-4f12-90ad-9675604d5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@FunctionTransformer\n",
    "def create_custom_features(df):\n",
    "    \"\"\"A custom transformer to generate useful features for the prediction.\"\"\"\n",
    "\n",
    "    df = df.copy()  # this is only useful during testing, so can be deleted\n",
    "\n",
    "    for column in df.columns:\n",
    "        df[f\"prev_{column}\"] = df.groupby(\"PULocationID\")[column].shift(-1)\n",
    "\n",
    "    time_var = df.index.get_level_values(\"rounded_time\")\n",
    "    df[\"year\"] = time_var.year\n",
    "    df[\"month\"] = time_var.month\n",
    "    df[\"dayofyear\"] = time_var.dayofyear\n",
    "    df[\"dayofmonth\"] = time_var.day\n",
    "    df[\"dayofweek\"] = time_var.dayofweek\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_log1p(df):\n",
    "    \"\"\"Also clips data to non-negative values.\"\"\"\n",
    "    return log1p(df)\n",
    "\n",
    "\n",
    "def inverse_apply_log1p(df):\n",
    "    \"\"\"Also clips data to non-negative values.\"\"\"\n",
    "    return exp(df) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e908ff-68f0-414c-8a0e-f4ff0c328eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=0),\n",
    "        [\"prev_trip_count\", \"prev_passenger_count\", \"prev_total_amount\"],\n",
    "    ),\n",
    "    (\n",
    "        OneHotEncoder(\n",
    "            categories=[range(265 + 1), range(6 + 1), range(31 + 1)],\n",
    "            handle_unknown=\"error\",\n",
    "        ),\n",
    "        [\"PULocationID\", \"dayofweek\", \"dayofmonth\"],\n",
    "    ),\n",
    "    (\n",
    "        \"passthrough\",\n",
    "        [\n",
    "            \"year\",\n",
    "            \"month\",\n",
    "            \"dayofyear\",\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "model = make_pipeline(\n",
    "    create_custom_features,\n",
    "    ct,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=XGBRegressor(n_jobs=-1),\n",
    "        func=apply_log1p,\n",
    "        inverse_func=inverse_apply_log1p,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9f7d31-1202-490c-a436-5a66914cec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test based on time\n",
    "mask_train = df.index.get_level_values(\"rounded_time\").year <= 2014\n",
    "mask_test = df.index.get_level_values(\"rounded_time\").year > 2014\n",
    "\n",
    "y_column = \"trip_count\"\n",
    "\n",
    "X = df\n",
    "y = df[y_column]\n",
    "\n",
    "X_train = X[mask_train].copy()\n",
    "y_train = y[mask_train].copy()\n",
    "\n",
    "X_test = X[mask_test].copy()\n",
    "y_test = y[mask_test].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c45073bb-8115-477b-8707-d2567930cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the alternatives are: a simple train-test split like below\n",
    "# # or the TimeSeriesSplit from sklearn, which is similar to the above, but introduces extra moving parts\n",
    "# X = df\n",
    "# y_column = \"trip_count\"\n",
    "# y = df[y_column]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7278a547-5b28-4fb5-9726-af61714c2b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function create_custom_features at 0x18f4e5700>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('simpleimputer',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant'),\n",
       "                                                  ['prev_trip_count',\n",
       "                                                   'prev_passenger_count',\n",
       "                                                   'prev_total_amount']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(categories=[range(0, 266),...\n",
       "                                                                   grow_policy=None,\n",
       "                                                                   importance_type=None,\n",
       "                                                                   interaction_constraints=None,\n",
       "                                                                   learning_rate=None,\n",
       "                                                                   max_bin=None,\n",
       "                                                                   max_cat_to_onehot=None,\n",
       "                                                                   max_delta_step=None,\n",
       "                                                                   max_depth=None,\n",
       "                                                                   max_leaves=None,\n",
       "                                                                   min_child_weight=None,\n",
       "                                                                   missing=nan,\n",
       "                                                                   monotone_constraints=None,\n",
       "                                                                   n_estimators=100,\n",
       "                                                                   n_jobs=-1,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   predictor=None,\n",
       "                                                                   random_state=None,\n",
       "                                                                   reg_alpha=None,\n",
       "                                                                   reg_lambda=None, ...)))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f981d5f-9977-4dec-8501-0c423692da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred, index_label=0):\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    from sklearn.metrics import (\n",
    "        mean_absolute_error,\n",
    "        mean_squared_error,\n",
    "        median_absolute_error,\n",
    "        r2_score,\n",
    "    )\n",
    "\n",
    "    median_ae = median_absolute_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return DataFrame(\n",
    "        {\"Median AE\": median_ae, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2},\n",
    "        index=[index_label],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "356b9ae1-f6f3-40f5-9365-018fcc8cad31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median AE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.783797</td>\n",
       "      <td>183.425914</td>\n",
       "      <td>565.447395</td>\n",
       "      <td>0.973802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Median AE         MAE        RMSE        R2\n",
       "0   6.783797  183.425914  565.447395  0.973802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "model_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86f8cf8d-2294-4da4-8f41-537f8e1e43eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Median AE         MAE        RMSE        R2\n",
      "0   6.770683  190.153663  583.813663  0.974528\n"
     ]
    }
   ],
   "source": [
    "print(model_performance(y_test, y_pred))\n",
    "#    Median AE         MAE        RMSE        R2\n",
    "# 0   6.770683  190.153663  583.813663  0.974528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24741766-3a17-4ccc-a0b8-3552d3ccd585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    333720.000000\n",
       "mean       1961.710886\n",
       "std        4050.947360\n",
       "min           1.000000\n",
       "25%           4.000000\n",
       "50%          32.000000\n",
       "75%        1022.000000\n",
       "max      100276.000000\n",
       "Name: trip_count, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[y_column].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef15f4-9b96-4c68-9b89-10e277567080",
   "metadata": {},
   "source": [
    "# hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8295714e-5fab-48f5-a632-ee47e9489e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Load our dataset, note ddf is persisted to avoid multiple recomputes\n",
    "    df = ddf.compute()\n",
    "\n",
    "    # split into train and test based on time\n",
    "    mask_train = df.index.get_level_values(\"rounded_time\").year <= 2014\n",
    "    mask_test = df.index.get_level_values(\"rounded_time\").year > 2014\n",
    "\n",
    "    y_column = \"trip_count\"\n",
    "\n",
    "    X = df\n",
    "    y = df[y_column]\n",
    "\n",
    "    X_train = X[mask_train].copy()\n",
    "    y_train = y[mask_train].copy()\n",
    "\n",
    "    X_test = X[mask_test].copy()\n",
    "    y_test = y[mask_test].copy()\n",
    "\n",
    "    # Get set of hyperparameters\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\n",
    "            \"objective\", [\"reg:squarederror\", \"count:poisson\"]\n",
    "        ),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\", \"gblinear\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-2, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "    # define the model with updated parameters and train it\n",
    "    model = make_pipeline(\n",
    "        create_custom_features,\n",
    "        ct,\n",
    "        TransformedTargetRegressor(\n",
    "            regressor=XGBRegressor(**param),\n",
    "            func=apply_log1p,\n",
    "            inverse_func=inverse_apply_log1p,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute and return a metric of interest\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "231bce5f-9c64-40e2-a60e-7299401563bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Dask-compatible Optuna storage class\n",
    "# note this: https://github.com/jrbourbeau/dask-optuna/issues/22\n",
    "storage = DaskStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "054e1c9f-bb35-4ca5-a692-c92ae2521d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-03 17:35:01,104]\u001b[0m A new study created in memory with name: no-name-023069b3-e58b-4125-a316-3ab74899b7f5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e06db7-f14a-4910-a106-b26835ab71bf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InMemoryStorage' object has no attribute 'set_study_direction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This will err, so use local storage instead\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/optuna/study.py:720\u001b[0m, in \u001b[0;36mcreate_study\u001b[0;34m(storage, sampler, pruner, study_name, direction, load_if_exists)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to direction.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 720\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_study_direction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_direction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/dask_optuna/storage.py:388\u001b[0m, in \u001b[0;36mDaskStorage.set_study_direction\u001b[0;34m(self, study_id, direction)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;129m@use_basestorage_doc\u001b[39m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_study_direction\u001b[39m(\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m, study_id: \u001b[38;5;28mint\u001b[39m, direction: study\u001b[38;5;241m.\u001b[39mStudyDirection\n\u001b[1;32m    387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptuna_set_study_direction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:310\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:364\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    363\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:349\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m         future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[0;32m--> 349\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     error[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/tornado/gen.py:762\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py:900\u001b[0m, in \u001b[0;36mPooledRPCCall.__getattr__.<locals>.send_recv_from_rpc\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m prev_name, comm\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m comm\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnectionPool.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m key\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m send_recv(comm\u001b[38;5;241m=\u001b[39mcomm, op\u001b[38;5;241m=\u001b[39mkey, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mreuse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddr, comm)\n",
      "File \u001b[0;32m~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py:693\u001b[0m, in \u001b[0;36msend_recv\u001b[0;34m(comm, reply, serializers, deserializers, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mdeserialize:\n\u001b[1;32m    692\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m clean_exception(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse)\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexception_text\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/envs/coiled/lib/python3.9/site-packages/distributed/core.py:516\u001b[0m, in \u001b[0;36mhandle_comm\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/coiled/lib/python3.9/site-packages/dask_optuna/storage.py:102\u001b[0m, in \u001b[0;36mset_study_direction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InMemoryStorage' object has no attribute 'set_study_direction'"
     ]
    }
   ],
   "source": [
    "# This will err, so use local storage instead\n",
    "study = create_study(direction=\"maximize\", storage=storage)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# AttributeError                            Traceback (most recent call last)\n",
    "# Input In [41], in <cell line: 2>()\n",
    "#       1 # Run 500 optimizations trial on our cluster\n",
    "# ----> 2 study = create_study(direction=\"maximize\", storage=storage)\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/optuna/study.py:720, in create_study(storage, sampler, pruner, study_name, direction, load_if_exists)\n",
    "#     717 else:\n",
    "#     718     raise ValueError(\"Please set either 'minimize' or 'maximize' to direction.\")\n",
    "# --> 720 study._storage.set_study_direction(study_id, _direction)\n",
    "#     722 return study\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/dask_optuna/storage.py:388, in DaskStorage.set_study_direction(self, study_id, direction)\n",
    "#     384 @use_basestorage_doc\n",
    "#     385 def set_study_direction(\n",
    "#     386     self, study_id: int, direction: study.StudyDirection\n",
    "#     387 ) -> None:\n",
    "# --> 388     return self.client.sync(\n",
    "#     389         self.client.scheduler.optuna_set_study_direction,\n",
    "#     390         study_id=study_id,\n",
    "#     391         direction=direction.name,\n",
    "#     392         storage_name=self.name,\n",
    "#     393     )\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:310, in SyncMethodMixin.sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\n",
    "#     308     return future\n",
    "#     309 else:\n",
    "# --> 310     return sync(\n",
    "#     311         self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
    "#     312     )\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:364, in sync(loop, func, callback_timeout, *args, **kwargs)\n",
    "#     362 if error[0]:\n",
    "#     363     typ, exc, tb = error[0]\n",
    "# --> 364     raise exc.with_traceback(tb)\n",
    "#     365 else:\n",
    "#     366     return result[0]\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:349, in sync.<locals>.f()\n",
    "#     347     if callback_timeout is not None:\n",
    "#     348         future = asyncio.wait_for(future, callback_timeout)\n",
    "# --> 349     result[0] = yield future\n",
    "#     350 except Exception:\n",
    "#     351     error[0] = sys.exc_info()\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/tornado/gen.py:762, in Runner.run(self)\n",
    "#     759 exc_info = None\n",
    "#     761 try:\n",
    "# --> 762     value = future.result()\n",
    "#     763 except Exception:\n",
    "#     764     exc_info = sys.exc_info()\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py:900, in PooledRPCCall.__getattr__.<locals>.send_recv_from_rpc(**kwargs)\n",
    "#     898 prev_name, comm.name = comm.name, \"ConnectionPool.\" + key\n",
    "#     899 try:\n",
    "# --> 900     return await send_recv(comm=comm, op=key, **kwargs)\n",
    "#     901 finally:\n",
    "#     902     self.pool.reuse(self.addr, comm)\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py:693, in send_recv(comm, reply, serializers, deserializers, **kwargs)\n",
    "#     691 if comm.deserialize:\n",
    "#     692     typ, exc, tb = clean_exception(**response)\n",
    "# --> 693     raise exc.with_traceback(tb)\n",
    "#     694 else:\n",
    "#     695     raise Exception(response[\"exception_text\"])\n",
    "\n",
    "# File /opt/conda/envs/coiled/lib/python3.9/site-packages/distributed/core.py:516, in handle_comm()\n",
    "\n",
    "# File /opt/conda/envs/coiled/lib/python3.9/site-packages/dask_optuna/storage.py:102, in set_study_direction()\n",
    "\n",
    "# AttributeError: 'InMemoryStorage' object has no attribute 'set_study_direction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80c2ac1d-e2c3-45ac-b701-2030db50d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-03 17:35:52,221]\u001b[0m Trial 0 finished with value: 0.9712460990505607 and parameters: {'objective': 'reg:squarederror', 'booster': 'gbtree', 'lambda': 0.2435279918173643, 'alpha': 0.0035880644926631405, 'eta': 0.08016637671811003}. Best is trial 0 with value: 0.9712460990505607.\u001b[0m\n",
      "\u001b[32m[I 2022-06-03 17:36:41,939]\u001b[0m Trial 1 finished with value: 0.9714510178144666 and parameters: {'objective': 'reg:squarederror', 'booster': 'gbtree', 'lambda': 0.06629462731236978, 'alpha': 0.0002242414202627213, 'eta': 0.0765882112865672}. Best is trial 1 with value: 0.9714510178144666.\u001b[0m\n",
      "\u001b[32m[I 2022-06-03 17:38:19,227]\u001b[0m Trial 2 finished with value: 0.965011341886657 and parameters: {'objective': 'reg:squarederror', 'booster': 'dart', 'lambda': 4.839783192855025e-05, 'alpha': 2.4044497485138587e-06, 'eta': 0.04629463439907404}. Best is trial 1 with value: 0.9714510178144666.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend(\"dask\"):\n",
    "    study.optimize(objective, n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b83b10c7-79b2-43a4-b930-564deddd3cac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'booster': 'gbtree', 'lambda': 0.06629462731236978, 'alpha': 0.0002242414202627213, 'eta': 0.0765882112865672}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "295d14dc-d3af-416a-895f-811ff1e825b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = make_pipeline(\n",
    "    create_custom_features,\n",
    "    ct,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=XGBRegressor(**best_params),\n",
    "        func=apply_log1p,\n",
    "        inverse_func=inverse_apply_log1p,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "798a46e2-4f4f-4b1a-87a5-1cc7d6b170be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function create_custom_features at 0x18f4e5700>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('simpleimputer',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant'),\n",
       "                                                  ['prev_trip_count',\n",
       "                                                   'prev_passenger_count',\n",
       "                                                   'prev_total_amount']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(categories=[range(0, 266),...\n",
       "                                                                   gamma=None,\n",
       "                                                                   gpu_id=None,\n",
       "                                                                   grow_policy=None,\n",
       "                                                                   importance_type=None,\n",
       "                                                                   interaction_constraints=None,\n",
       "                                                                   lambda=0.06629462731236978,\n",
       "                                                                   learning_rate=None,\n",
       "                                                                   max_bin=None,\n",
       "                                                                   max_cat_to_onehot=None,\n",
       "                                                                   max_delta_step=None,\n",
       "                                                                   max_depth=None,\n",
       "                                                                   max_leaves=None,\n",
       "                                                                   min_child_weight=None,\n",
       "                                                                   missing=nan,\n",
       "                                                                   monotone_constraints=None,\n",
       "                                                                   n_estimators=100,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   predictor=None, ...)))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b0de1db-34b3-4a8e-9607-3bd4fb46404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Median AE         MAE        RMSE        R2\n",
      "0   7.165927  187.004637  590.276149  0.971451\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(model_performance(y_test, y_pred))\n",
    "#    Median AE         MAE        RMSE        R2\n",
    "# 0   6.770683  190.153663  583.813663  0.974528\n",
    "# THIS MODEL IS PERFORMING WORSE\n",
    "#    Median AE         MAE        RMSE        R2\n",
    "# 0   7.165927  187.004637  590.276149  0.971451"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coiled_taxi] *",
   "language": "python",
   "name": "conda-env-coiled_taxi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
