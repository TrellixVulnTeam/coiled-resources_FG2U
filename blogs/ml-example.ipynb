{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5e507d-8b43-4d55-b297-248aed014d85",
   "metadata": {},
   "source": [
    "Notebook goal:\n",
    "\n",
    "- predict the tip size\n",
    "\n",
    "Structure:\n",
    "\n",
    "- load the data\n",
    "- transform into required shape\n",
    "- train (note will use a hard, time-based split)\n",
    "- predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91a773-4fce-4a24-8357-0aad19fd1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import coiled\n",
    "# coiled.create_software_environment(\n",
    "#     name=\"ml-with-dask\",\n",
    "#     account=\"coiled-examples\",\n",
    "#     conda=\"/Users/rpelgrim/Documents/git/coiled-resources/envs/ml-example.yml\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfecffa-151b-4693-be01-997b68052a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a63c5e8a68d4f30b0266121832a8dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from coiled import Cluster\n",
    "from distributed import Client\n",
    "\n",
    "cluster = Cluster(\n",
    "    name=\"ml-with-dask\",\n",
    "    software=\"coiled-examples/ml-with-dask\",\n",
    "    n_workers=10,\n",
    "    worker_cpu=8,\n",
    "    worker_memory=\"31GiB\",\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09bd158-1e76-44e9-8241-06d582c13e97",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900f5e78-db98-458a-90bf-ae1e2902c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask_optuna import DaskStorage\n",
    "from joblib import parallel_backend\n",
    "from numpy import exp, log1p\n",
    "from optuna import create_study\n",
    "from sklearn.compose import TransformedTargetRegressor, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, PolynomialFeatures\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225f97d-cf6a-4cb1-b22b-f11f890527ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612c0afc-7bba-4087-aae5-baec15437cce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load data and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73c5a75-d7ef-4a9c-a4b0-6b82fbca1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_aggregate(year, month):\n",
    "    \"\"\"Load data for a particular year/month and aggregate to the required format.\"\"\"\n",
    "\n",
    "    # optimize data usage by loading columns of interest only\n",
    "    use_cols = [\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"tpep_pickup_datetime\",\n",
    "        # \"tpep_dropoff_datetime\",\n",
    "        \"passenger_count\",\n",
    "        \"total_amount\",\n",
    "        # \"trip_distance\",\n",
    "        # \"tip_amount\",\n",
    "    ]\n",
    "\n",
    "    PATH_DATA = \"s3://nyc-tlc/trip data/yellow_tripdata_{year}-{month:02}*.parquet\"\n",
    "\n",
    "    ddf = dd.read_parquet(PATH_DATA.format(year=year, month=month), columns=use_cols)\n",
    "\n",
    "    frequency = \"1D\"\n",
    "    ddf[\"rounded_time\"] = ddf[\"tpep_pickup_datetime\"].dt.floor(frequency)\n",
    "\n",
    "    ddf[\"trip_count\"] = 1\n",
    "\n",
    "    # aggregate the data to necessary format\n",
    "    aggregations = {\n",
    "        \"trip_count\": \"sum\",\n",
    "        \"passenger_count\": \"sum\",\n",
    "        \"total_amount\": \"sum\",\n",
    "    }\n",
    "\n",
    "    ddf_agg = ddf.groupby([\"rounded_time\", \"PULocationID\"]).agg(aggregations)\n",
    "    for c in ddf_agg.columns:\n",
    "        ddf_agg[c] = ddf_agg[c].clip(lower=0)\n",
    "\n",
    "    return ddf_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b60f613-8d7d-4e18-b3ce-1647c1b2b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.concat(\n",
    "    [\n",
    "        load_and_aggregate(year, month)\n",
    "        for year in range(2012, 2016 + 1)\n",
    "        for month in range(1, 12 + 1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b6b07e-050d-4d70-8e9e-3f50468fa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist to avoid recomputes when using optuna\n",
    "ddf = ddf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff86c37-11e4-46e4-a3bc-1e9994f7d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient parallel processing and aggregation\n",
    "# the result is small, so can load it into memory\n",
    "df = ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df220733-e138-4098-8a11-ef51ab976f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>trip_count</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rounded_time</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2012-01-01</th>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>2880.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>39.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>994</td>\n",
       "      <td>1493</td>\n",
       "      <td>12158.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1096</td>\n",
       "      <td>1513</td>\n",
       "      <td>14682.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           trip_count  passenger_count  total_amount\n",
       "rounded_time PULocationID                                           \n",
       "2012-01-01   1                     41               66       2880.73\n",
       "             2                      1                2          9.90\n",
       "             3                      2                3         39.10\n",
       "             4                    994             1493      12158.62\n",
       "             7                   1096             1513      14682.94"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ad43c-0fbd-4f05-bfd5-281185bc2ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "062c0ecf-88bf-414f-a381-af949c29fa25",
   "metadata": {},
   "source": [
    "# add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5edfe53-3fc0-4f12-90ad-9675604d5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@FunctionTransformer\n",
    "def create_custom_features(df):\n",
    "    \"\"\"A custom transformer to generate useful features for the prediction.\"\"\"\n",
    "\n",
    "    df = df.copy()  # this is only useful during testing, so can be deleted\n",
    "\n",
    "    for column in df.columns:\n",
    "        df[f\"prev_{column}\"] = df.groupby(\"PULocationID\")[column].shift(-1)\n",
    "\n",
    "    time_var = df.index.get_level_values(\"rounded_time\")\n",
    "    df[\"year\"] = time_var.year\n",
    "    df[\"month\"] = time_var.month\n",
    "    df[\"dayofyear\"] = time_var.dayofyear\n",
    "    df[\"dayofmonth\"] = time_var.day\n",
    "    df[\"dayofweek\"] = time_var.dayofweek\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_log1p(df):\n",
    "    \"\"\"Also clips data to non-negative values.\"\"\"\n",
    "    return log1p(df)\n",
    "\n",
    "\n",
    "def inverse_apply_log1p(df):\n",
    "    \"\"\"Also clips data to non-negative values.\"\"\"\n",
    "    return exp(df) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e908ff-68f0-414c-8a0e-f4ff0c328eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=0),\n",
    "        [\"prev_trip_count\", \"prev_passenger_count\", \"prev_total_amount\"],\n",
    "    ),\n",
    "    (\n",
    "        OneHotEncoder(\n",
    "            categories=[range(265 + 1), range(6 + 1), range(31 + 1)],\n",
    "            handle_unknown=\"error\",\n",
    "        ),\n",
    "        [\"PULocationID\", \"dayofweek\", \"dayofmonth\"],\n",
    "    ),\n",
    "    (\n",
    "        \"passthrough\",\n",
    "        [\n",
    "            \"year\",\n",
    "            \"month\",\n",
    "            \"dayofyear\",\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "model = make_pipeline(\n",
    "    create_custom_features,\n",
    "    ct,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=XGBRegressor(n_jobs=-1),\n",
    "        func=apply_log1p,\n",
    "        inverse_func=inverse_apply_log1p,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a9f7d31-1202-490c-a436-5a66914cec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test based on time\n",
    "mask_train = df.index.get_level_values(\"rounded_time\").year <= 2014\n",
    "mask_test = df.index.get_level_values(\"rounded_time\").year > 2014\n",
    "\n",
    "y_column = \"trip_count\"\n",
    "\n",
    "X = df\n",
    "y = df[y_column]\n",
    "\n",
    "X_train = X[mask_train].copy()\n",
    "y_train = y[mask_train].copy()\n",
    "\n",
    "X_test = X[mask_test].copy()\n",
    "y_test = y[mask_test].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c45073bb-8115-477b-8707-d2567930cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the alternatives are: a simple train-test split like below\n",
    "# # or the TimeSeriesSplit from sklearn, which is similar to the above, but introduces extra moving parts\n",
    "# X = df\n",
    "# y_column = \"trip_count\"\n",
    "# y = df[y_column]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7278a547-5b28-4fb5-9726-af61714c2b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function create_custom_features at 0x16a1084c0>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('simpleimputer',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant'),\n",
       "                                                  ['prev_trip_count',\n",
       "                                                   'prev_passenger_count',\n",
       "                                                   'prev_total_amount']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(categories=[range(0, 266),...\n",
       "                                                                   interaction_constraints=None,\n",
       "                                                                   learning_rate=None,\n",
       "                                                                   max_delta_step=None,\n",
       "                                                                   max_depth=None,\n",
       "                                                                   min_child_weight=None,\n",
       "                                                                   missing=nan,\n",
       "                                                                   monotone_constraints=None,\n",
       "                                                                   n_estimators=100,\n",
       "                                                                   n_jobs=-1,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   predictor=None,\n",
       "                                                                   random_state=None,\n",
       "                                                                   reg_alpha=None,\n",
       "                                                                   reg_lambda=None,\n",
       "                                                                   scale_pos_weight=None,\n",
       "                                                                   subsample=None,\n",
       "                                                                   tree_method=None,\n",
       "                                                                   validate_parameters=None,\n",
       "                                                                   verbosity=None)))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f981d5f-9977-4dec-8501-0c423692da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred, index_label=0):\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    from sklearn.metrics import (\n",
    "        mean_absolute_error,\n",
    "        mean_squared_error,\n",
    "        median_absolute_error,\n",
    "        r2_score,\n",
    "    )\n",
    "\n",
    "    median_ae = median_absolute_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return DataFrame(\n",
    "        {\"Median AE\": median_ae, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2},\n",
    "        index=[index_label],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "356b9ae1-f6f3-40f5-9365-018fcc8cad31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median AE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.783797</td>\n",
       "      <td>183.425914</td>\n",
       "      <td>565.447395</td>\n",
       "      <td>0.973802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Median AE         MAE        RMSE        R2\n",
       "0   6.783797  183.425914  565.447395  0.973802"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "model_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86f8cf8d-2294-4da4-8f41-537f8e1e43eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Median AE         MAE        RMSE        R2\n",
      "0   6.783797  183.425914  565.447395  0.973802\n"
     ]
    }
   ],
   "source": [
    "print(model_performance(y_test, y_pred))\n",
    "#    Median AE         MAE        RMSE        R2\n",
    "# 0   6.770683  190.153663  583.813663  0.974528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24741766-3a17-4ccc-a0b8-3552d3ccd585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    414853.000000\n",
       "mean       1894.150367\n",
       "std        3920.652716\n",
       "min           1.000000\n",
       "25%           4.000000\n",
       "50%          31.000000\n",
       "75%         984.000000\n",
       "max      100276.000000\n",
       "Name: trip_count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[y_column].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef15f4-9b96-4c68-9b89-10e277567080",
   "metadata": {},
   "source": [
    "# hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8295714e-5fab-48f5-a632-ee47e9489e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Load our dataset, note ddf is persisted to avoid multiple recomputes\n",
    "    df = ddf.compute()\n",
    "\n",
    "    # split into train and test based on time\n",
    "    mask_train = df.index.get_level_values(\"rounded_time\").year <= 2014\n",
    "    mask_test = df.index.get_level_values(\"rounded_time\").year > 2014\n",
    "\n",
    "    y_column = \"trip_count\"\n",
    "\n",
    "    X = df\n",
    "    y = df[y_column]\n",
    "\n",
    "    X_train = X[mask_train].copy()\n",
    "    y_train = y[mask_train].copy()\n",
    "\n",
    "    X_test = X[mask_test].copy()\n",
    "    y_test = y[mask_test].copy()\n",
    "\n",
    "    # Get set of hyperparameters\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\n",
    "            \"objective\", [\"reg:squarederror\", \"count:poisson\"]\n",
    "        ),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\", \"gblinear\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-2, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "    # define the model with updated parameters and train it\n",
    "    model = make_pipeline(\n",
    "        create_custom_features,\n",
    "        ct,\n",
    "        TransformedTargetRegressor(\n",
    "            regressor=XGBRegressor(**param),\n",
    "            func=apply_log1p,\n",
    "            inverse_func=inverse_apply_log1p,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute and return a metric of interest\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da46d7d-d72e-406b-8e47-8b1afc36ca70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8e44956-7fcb-4e55-9a99-c1c04b887265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(trip_count         0\n",
       " passenger_count    0\n",
       " total_amount       0\n",
       " dtype: int64,\n",
       " 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cac73059-bb08-4094-b0c3-8f5c549e064d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b170d-3cd9-4c1a-8fc2-fca63929c973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2237e189-a72b-418a-9389-6919d1bf1126",
   "metadata": {},
   "source": [
    "### Dask-compatible Optuna storage class errors out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "231bce5f-9c64-40e2-a60e-7299401563bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Dask-compatible Optuna storage class\n",
    "# note this: https://github.com/jrbourbeau/dask-optuna/issues/22\n",
    "# DON'T USE THIS WHEN STORING LOCALLY\n",
    "storage = DaskStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7e06db7-f14a-4910-a106-b26835ab71bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This erred out for Sultan, so use local storage instead\n",
    "study = create_study(direction=\"maximize\", storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a20b4-e935-4ea7-b468-851dd316f9cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# AttributeError                            Traceback (most recent call last)\n",
    "# Input In [41], in <cell line: 2>()\n",
    "#       1 # Run 500 optimizations trial on our cluster\n",
    "# ----> 2 study = create_study(direction=\"maximize\", storage=storage)\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/optuna/study.py:720, in create_study(storage, sampler, pruner, study_name, direction, load_if_exists)\n",
    "#     717 else:\n",
    "#     718     raise ValueError(\"Please set either 'minimize' or 'maximize' to direction.\")\n",
    "# --> 720 study._storage.set_study_direction(study_id, _direction)\n",
    "#     722 return study\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/dask_optuna/storage.py:388, in DaskStorage.set_study_direction(self, study_id, direction)\n",
    "#     384 @use_basestorage_doc\n",
    "#     385 def set_study_direction(\n",
    "#     386     self, study_id: int, direction: study.StudyDirection\n",
    "#     387 ) -> None:\n",
    "# --> 388     return self.client.sync(\n",
    "#     389         self.client.scheduler.optuna_set_study_direction,\n",
    "#     390         study_id=study_id,\n",
    "#     391         direction=direction.name,\n",
    "#     392         storage_name=self.name,\n",
    "#     393     )\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:310, in SyncMethodMixin.sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\n",
    "#     308     return future\n",
    "#     309 else:\n",
    "# --> 310     return sync(\n",
    "#     311         self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
    "#     312     )\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:364, in sync(loop, func, callback_timeout, *args, **kwargs)\n",
    "#     362 if error[0]:\n",
    "#     363     typ, exc, tb = error[0]\n",
    "# --> 364     raise exc.with_traceback(tb)\n",
    "#     365 else:\n",
    "#     366     return result[0]\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:349, in sync.<locals>.f()\n",
    "#     347     if callback_timeout is not None:\n",
    "#     348         future = asyncio.wait_for(future, callback_timeout)\n",
    "# --> 349     result[0] = yield future\n",
    "#     350 except Exception:\n",
    "#     351     error[0] = sys.exc_info()\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/tornado/gen.py:762, in Runner.run(self)\n",
    "#     759 exc_info = None\n",
    "#     761 try:\n",
    "# --> 762     value = future.result()\n",
    "#     763 except Exception:\n",
    "#     764     exc_info = sys.exc_info()\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py:900, in PooledRPCCall.__getattr__.<locals>.send_recv_from_rpc(**kwargs)\n",
    "#     898 prev_name, comm.name = comm.name, \"ConnectionPool.\" + key\n",
    "#     899 try:\n",
    "# --> 900     return await send_recv(comm=comm, op=key, **kwargs)\n",
    "#     901 finally:\n",
    "#     902     self.pool.reuse(self.addr, comm)\n",
    "\n",
    "# File ~/miniconda3/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py:693, in send_recv(comm, reply, serializers, deserializers, **kwargs)\n",
    "#     691 if comm.deserialize:\n",
    "#     692     typ, exc, tb = clean_exception(**response)\n",
    "# --> 693     raise exc.with_traceback(tb)\n",
    "#     694 else:\n",
    "#     695     raise Exception(response[\"exception_text\"])\n",
    "\n",
    "# File /opt/conda/envs/coiled/lib/python3.9/site-packages/distributed/core.py:516, in handle_comm()\n",
    "\n",
    "# File /opt/conda/envs/coiled/lib/python3.9/site-packages/dask_optuna/storage.py:102, in set_study_direction()\n",
    "\n",
    "# AttributeError: 'InMemoryStorage' object has no attribute 'set_study_direction'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799521c-ad37-44d0-8ccb-80d1e9a13a6e",
   "metadata": {},
   "source": [
    "### So Work Locally Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054e1c9f-bb35-4ca5-a692-c92ae2521d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-08 15:27:06,113]\u001b[0m A new study created in memory with name: no-name-c3ee0b4d-4d8b-42ca-b4a0-40069dca78a2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0665fc-a8e7-4769-b9b6-1f04c6803637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1532d3b-1477-4190-93d3-b5e528d8cbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58d2d7-d538-400f-8528-5527eba64855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519f205-c669-42e5-8f4f-a5acedc0fafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80c2ac1d-e2c3-45ac-b701-2030db50d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-06-08 15:27:37,747]\u001b[0m Trial 0 failed because of the following error: KilledWorker(\"('read-parquet-1fb47b1256515f163c79cb7f23639dfe', 0)\", <WorkerState 'tls://10.4.14.148:40641', name: ml-with-dask-worker-2e9d89cfc3, status: closed, memory: 0, processing: 14>)\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"/var/folders/ky/bqjn_gxn1xv0cn_8q5xvp3q40000gn/T/ipykernel_2391/256758797.py\", line 4, in objective\n",
      "    df = ddf.compute()\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/dask/base.py\", line 288, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/dask/base.py\", line 571, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/client.py\", line 2746, in get\n",
      "    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/client.py\", line 1946, in gather\n",
      "    return self.sync(\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py\", line 310, in sync\n",
      "    return sync(\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py\", line 364, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py\", line 349, in f\n",
      "    result[0] = yield future\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/tornado/gen.py\", line 762, in run\n",
      "    value = future.result()\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/client.py\", line 1811, in _gather\n",
      "    raise exception.with_traceback(traceback)\n",
      "distributed.scheduler.KilledWorker: (\"('read-parquet-1fb47b1256515f163c79cb7f23639dfe', 0)\", <WorkerState 'tls://10.4.14.148:40641', name: ml-with-dask-worker-2e9d89cfc3, status: closed, memory: 0, processing: 14>)\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "(\"('read-parquet-1fb47b1256515f163c79cb7f23639dfe', 0)\", <WorkerState 'tls://10.4.14.148:40641', name: ml-with-dask-worker-2e9d89cfc3, status: closed, memory: 0, processing: 14>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/optuna/study.py:306\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    230\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/optuna/_optimize.py:55\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/optuna/_optimize.py:156\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/optuna/_optimize.py:189\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    186\u001b[0m trial_number \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mnumber\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# Register the last intermediate value if present as the value of the trial.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# TODO(hvy): Whether a pruned trials should have an actual value can be discussed.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mget_trial(trial_id)\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Load our dataset, note ddf is persisted to avoid multiple recomputes\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mddf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# split into train and test based on time\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     mask_train \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrounded_time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2014\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/dask/base.py:288\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/dask/base.py:571\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    569\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 571\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/client.py:2746\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2744\u001b[0m         should_rejoin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2746\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2748\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/client.py:1946\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1945\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:310\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:364\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    363\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/utils.py:349\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m         future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[0;32m--> 349\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     error[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/tornado/gen.py:762\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/client.py:1811\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1809\u001b[0m         exc \u001b[38;5;241m=\u001b[39m CancelledError(key)\n\u001b[1;32m   1810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKilledWorker\u001b[0m: (\"('read-parquet-1fb47b1256515f163c79cb7f23639dfe', 0)\", <WorkerState 'tls://10.4.14.148:40641', name: ml-with-dask-worker-2e9d89cfc3, status: closed, memory: 0, processing: 14>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n",
      "distributed.deploy.cluster - WARNING - Failed to sync cluster info multiple times - perhaps there's a connection issue? Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 409, in connect\n",
      "    stream = await self.client.connect(\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/tornado/tcpclient.py\", line 275, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/asyncio/tasks.py\", line 490, in wait_for\n",
      "    return fut.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/asyncio/tasks.py\", line 492, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/deploy/cluster.py\", line 131, in _sync_cluster_info\n",
      "    await self.scheduler_comm.set_metadata(\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py\", line 822, in send_recv_from_rpc\n",
      "    comm = await self.live_comm()\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/core.py\", line 779, in live_comm\n",
      "    comm = await connect(\n",
      "  File \"/Users/rpelgrim/mambaforge/envs/coiled_taxi/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tls://34.239.1.108:8786 after 30 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with parallel_backend(\"dask\"):\n",
    "    study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83b10c7-79b2-43a4-b930-564deddd3cac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'booster': 'gbtree', 'lambda': 2.1566103715315003e-06, 'alpha': 0.0009330665005152326, 'eta': 0.8743753776465254}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "295d14dc-d3af-416a-895f-811ff1e825b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = make_pipeline(\n",
    "    create_custom_features,\n",
    "    ct,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=XGBRegressor(**best_params),\n",
    "        func=apply_log1p,\n",
    "        inverse_func=inverse_apply_log1p,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "798a46e2-4f4f-4b1a-87a5-1cc7d6b170be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function create_custom_features at 0x16a3be430>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('simpleimputer',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant'),\n",
       "                                                  ['prev_trip_count',\n",
       "                                                   'prev_passenger_count',\n",
       "                                                   'prev_total_amount']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(categories=[range(0, 266),...\n",
       "                                                                   interaction_constraints=None,\n",
       "                                                                   lambda=2.1566103715315003e-06,\n",
       "                                                                   learning_rate=None,\n",
       "                                                                   max_delta_step=None,\n",
       "                                                                   max_depth=None,\n",
       "                                                                   min_child_weight=None,\n",
       "                                                                   missing=nan,\n",
       "                                                                   monotone_constraints=None,\n",
       "                                                                   n_estimators=100,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   predictor=None,\n",
       "                                                                   random_state=None,\n",
       "                                                                   reg_alpha=None,\n",
       "                                                                   reg_lambda=None,\n",
       "                                                                   scale_pos_weight=None,\n",
       "                                                                   subsample=None,\n",
       "                                                                   tree_method=None,\n",
       "                                                                   validate_parameters=None, ...)))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b0de1db-34b3-4a8e-9607-3bd4fb46404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Median AE         MAE       RMSE        R2\n",
      "0   7.057741  187.265314  583.53562  0.972099\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(model_performance(y_test, y_pred))\n",
    "#    Median AE         MAE        RMSE        R2\n",
    "# 0   6.770683  190.153663  583.813663  0.974528\n",
    "# THIS MODEL IS PERFORMING WORSE\n",
    "#    Median AE         MAE        RMSE        R2\n",
    "# 0   7.165927  187.004637  590.276149  0.971451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407b398-adf1-40cf-952b-cf0ddd72f212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coiled-taxi",
   "language": "python",
   "name": "coiled-taxi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
